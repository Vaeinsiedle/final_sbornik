{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8943242,"sourceType":"datasetVersion","datasetId":5381329}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Сборный проект-4\n\nВам поручено разработать демонстрационную версию поиска изображений по запросу.\n\nДля демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n\n### Описание данных\n\nДанные лежат в папке `/datasets/image_search/` или доступны по [ссылке](https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip).\n\nВ файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n\nВ папке `train_images` содержатся изображения для тренировки модели.\n\nВ файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n\n1. Имя файла изображения.\n2. Идентификатор описания.\n3. Доля людей, подтвердивших, что описание соответствует изображению.\n4. Количество человек, подтвердивших, что описание соответствует изображению.\n5. Количество человек, подтвердивших, что описание не соответствует изображению.\n\nВ файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n\n1. Имя файла изображения.\n2. Идентификатор описания.\n\n3, 4, 5 — оценки трёх экспертов.\n\nЭксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n\nВ файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n\nВ папке `test_images` содержатся изображения для тестирования модели.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Исследовательский анализ данных\n\nНаш датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n\nВ файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи вы должны эти оценки агрегировать — превратить в одну. Существует несколько способов агрегации оценок, самый простой — голосование большинства: за какую оценку проголосовала большая часть экспертов (в нашем случае 2 или 3), та оценка и ставится как итоговая. Поскольку число экспертов меньше числа классов, может случиться, что каждый эксперт поставит разные оценки, например: 1, 4, 2. В таком случае данную пару изображение-текст можно исключить из датасета.\n\nВы можете воспользоваться другим методом агрегации оценок или придумать свой.\n\nВ файле с краудсорсинговыми оценками информация расположена в таком порядке:\n\n1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке.\n2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n\nПосле анализа экспертных и краудсорсинговых оценок выберите либо одну из них, либо объедините их в одну по какому-то критерию: например, оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.\n\nВаша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport pickle\n\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nnltk.download('stopwords') # поддерживает удаление стоп-слов\nnltk.download('punkt') # делит текст на список предложений\nnltk.download('wordnet') # проводит лемматизацию\nnltk.download('omw-1.4')\n\nfrom PIL import Image\n\nfrom tensorflow.keras.layers import (Dense, GlobalAveragePooling2D, Flatten, Dropout, BatchNormalization)\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.resnet import ResNet50\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras_nlp\n\nfrom tqdm import notebook\n\nfrom sklearn.model_selection import GroupShuffleSplit, GridSearchCV, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.svm import LinearSVR\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\n\n\nimport glob","metadata":{"execution":{"iopub.status.busy":"2024-07-14T12:05:25.088892Z","iopub.execute_input":"2024-07-14T12:05:25.089673Z","iopub.status.idle":"2024-07-14T12:05:25.100042Z","shell.execute_reply.started":"2024-07-14T12:05:25.089629Z","shell.execute_reply":"2024-07-14T12:05:25.098899Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-07-14T12:05:25.114179Z","iopub.execute_input":"2024-07-14T12:05:25.115225Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\nreplace /usr/share/nltk_data/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename: ","output_type":"stream"}]},{"cell_type":"code","source":"PATH = '/kaggle/input/dt-photos/to_upload'\nSEED = 31416\nBLOCK = ['teenage', 'baby', 'child', 'teenager', 'girl', 'boy', 'kid']\n\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_df(path=PATH) -> pd.DataFrame:\n\n    '''читаем датафреймы из указанной директории'''\n    \n    df_train = pd.read_csv(Path(path, 'train_dataset.csv'))\n    df_crowd = pd.read_csv(Path(path, 'CrowdAnnotations.tsv'), sep='\\t',\n                           names=['image', 'query_id', 'share_pos', 'count_pos', 'count_neg'])\n    df_expert = pd.read_csv(Path(path, 'ExpertAnnotations.tsv'), sep='\\t',\n                           names=['image', 'query_id', 'first', 'second', 'third'])\n    df_queries = pd.read_csv(Path(path, 'test_queries.csv'), index_col=[0], sep='|')\n    df_images = pd.read_csv(Path(path, 'test_images.csv'), sep='|')\n    \n    return df_train, df_crowd, df_expert, df_queries, df_images\n\ndf_train, df_crowd, df_expert, df_queries, df_images = read_df()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_train.head(), df_crowd.head(), df_expert.head(), df_queries.head(), df_images.head())\ndisplay(df_train.describe(), df_crowd.describe(), df_expert.describe(), df_queries.describe(), df_images.describe())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Количество уникальных фото на трейне:', len(df_train['image'].unique()))\nprint('Количество уникальных фото на тесте:', len(df_queries['image'].unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Количество уникальных запросов на тесте:', df_queries.drop_duplicates().shape[0])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Количество уникальных сочетаний фото-текст оцененных экспертами:', df_expert.drop_duplicates().shape[0])\nprint('Количество уникальных сочетаний фото-текст оцененных людьми:', df_crowd.drop_duplicates().shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Уникальных текстовых описаний в трейне:', len(set(df_train['query_text'])))\nprint('Уникальных текстовых описаний в тесте:', len(set(df_queries['query_text'])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Уникальных картинок в трейне:', len(set(df_train['image'])))\nprint('Уникальных картинок в тесте:', len(set(df_queries['image'])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples_train = list(df_train['image'].sample(8))\nsamples_test = list(df_queries['image'].sample(8))\n\nfig = plt.figure(figsize=(10,10))\nfor i in range(8):\n    fig.add_subplot(4, 4, i+1)\n    image = Image.open(Path('/kaggle/input/dt-photos/train_images', 'train_images', samples_train[i]))\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout()\nfor i in range(8):\n    fig.add_subplot(4, 4, i+9)\n    image = Image.open(Path(PATH, 'test_images', samples_test[i]))\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Вывод ##","metadata":{}},{"cell_type":"markdown","source":"- Мы загрузили и ознакомились с данными.\n- Данные в порядке в целом , особых аномалий – нет.","metadata":{}},{"cell_type":"markdown","source":"## Аггрегация оценок ##\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndef expert_aggregate(row) -> object:\n    '''Агрегируем экспертную оценку усреднением ответов и сведением к диапазону [0,1]'''\n\n    # Проверяем, если все три оценки разные\n    if row['first'] != row['second'] and row['second'] != row['third'] and row['first'] != row['third']:\n        # Суммируем все три оценки\n        sum_scores = row['first'] + row['second'] + row['third']\n        # Вычитаем 3, чтобы преобразовать диапазон 3-9 в 0-6\n        adjusted_sum = sum_scores - 3\n        # Делим на 3 для получения среднего и еще раз на 3 для приведения к диапазону [0, 1]\n        row['expert_score'] = adjusted_sum / 3 / 3\n\n    else:  # Если хотя бы две оценки совпадают\n        # Находим наиболее частую оценку (голосование большинства)\n        majority_vote = max(set([row['first'], row['second'], row['third']]), key=[row['first'], row['second'], row['third']].count)\n        # Вычитаем 1, чтобы преобразовать диапазон 1-3 в 0-2\n        adjusted_majority_vote = majority_vote - 1\n        # Делим на 3 для приведения к диапазону [0, 1]\n        row['expert_score'] = adjusted_majority_vote / 3\n\n    return row\n\ndf_expert = df_expert.apply(expert_aggregate, axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Объединим оба блока с оценками, а именно людей и экспертов. Также дадим вес каждой оценке, вес экспертов будет равен 70% , а людей 30%.**","metadata":{}},{"cell_type":"code","source":"df_scores = pd.merge(df_expert, df_crowd, how='outer', on=['image', 'query_id'])\n\ndef score_aggregate(row) -> object:\n\n    '''аггрегируем оценки людей и экспертов'''\n\n    if np.isnan(row['expert_score']):\n        row['score'] = row['share_pos']\n    elif np.isnan(row['share_pos']):\n        row['score'] = row['expert_score']\n    else:\n        row['score'] = row['expert_score'] * 0.7 + row['share_pos'] * 0.3\n        \n    return row\n\ndf_scores = df_scores.apply(score_aggregate, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_scores['score'].isna().value_counts())\ndf_scores['score'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Добавим цели в наши датасеты.**\n\n","metadata":{}},{"cell_type":"code","source":"df_train = pd.merge(df_train, df_scores[['image', 'query_id', 'score']], how='outer', on=['image', 'query_id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_fill = df_train[df_train['query_text'].notna()]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Заполним пропуски в описании после добавления оценок людей.**","metadata":{}},{"cell_type":"code","source":"def fill_text(row) -> object:\n\n    '''заполняем пропуски текстов в тренировочном наборе данных'''\n\n    if pd.isnull(row['query_text']):\n        texts = to_fill[to_fill['query_id'] == row['query_id']]['query_text']\n        if len(texts) > 0:\n            row['query_text'] = texts.iloc[0]\n\n    return row\n\ndf_train = df_train.apply(fill_text, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Лемматизация ##","metadata":{}},{"cell_type":"code","source":"lemmatize = nltk.WordNetLemmatizer()\n\ndef get_lemmas(text) -> list:\n\n    '''очищаем текст и превращаем в список лемм'''\n\n    text = re.sub('[^a-zA-Z]', ' ', text).lower() # удаляем неалфавитные символы, приводим к нижнему регистру\n    text = nltk.word_tokenize(text, language = 'english') # токенизируем слова\n    text = [lemmatize.lemmatize(word) for word in text] # лемматирзируем слова\n\n    return text\n\ndef cleaning(row) -> object:\n\n    '''делаем разметку текстов для блокирования'''\n\n    text = get_lemmas(row['query_text'])\n    if [i for i in text if i in BLOCK]:\n        row['to_block'] = 1\n    else:\n        row['to_block'] = 0\n\n    return row","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time df_train = df_train.apply(cleaning, axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Проверим нашу функцию и выведем неподходящие картинки.**","metadata":{}},{"cell_type":"code","source":"\nsamples = list(df_train[df_train['to_block'] == 1]['query_id'].sample(16))\nsamples = [i[:-2] for i in samples]\n\nfig = plt.figure(figsize=(10,10))\nfor i in range(16):\n    fig.add_subplot(4, 4, i+1)\n    image = Image.open(Path(PATH, 'train_images', samples[i]))\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}